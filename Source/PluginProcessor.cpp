/*
  ==============================================================================

	This file was auto-generated by the Introjucer!

	It contains the basic framework code for a JUCE plugin processor.

  ==============================================================================
*/

#include "PluginProcessor.h"
#include "PluginEditor.h"

// Default parameter values
const float defaultOutputGain = 1.0f;
const float defaultSemitones = 0.0f;
const float defaultCents = 0.0f;
const float defaultType = bq_type_lowpass;
const float defaultCutoff = 20.0f;
const float defaultResonance = 0.7f;
const float defaultPeakGain = 0.0f;

//==============================================================================
SynthesizerAudioProcessor::SynthesizerAudioProcessor()
{
	// Set up the parameters. The base class will delete them when not needed.
	addParameter(outputGain = new FloatParameter{ defaultOutputGain, "Output Gain" });
	addParameter(semitones = new FloatParameter{ defaultSemitones, "Semitones" });
	addParameter(cents = new FloatParameter{ defaultCents, "Cents" });
	addParameter(filterType = new FloatParameter{ defaultType, "Filter Type" });
	addParameter(cutoff = new FloatParameter{ defaultCutoff, "Cutoff" });
	addParameter(resonance = new FloatParameter{ defaultResonance, "Resonance" });
	addParameter(peakGaindB = new FloatParameter{ defaultPeakGain, "Peak Gain" });
	
	lastUIWidth = 400;
	lastUIHeight = 200;

	lastPosInfo.resetToDefault();

	// Initialize the synth:
	for (int i = 4; --i >= 0;)
		synth.addVoice(new SineWaveVoice{});	// These voices will play the SineWaveSound

	synth.addSound(new SineWaveSound{});
}

SynthesizerAudioProcessor::~SynthesizerAudioProcessor()
{
}

//==============================================================================
const String SynthesizerAudioProcessor::getInputChannelName (int channelIndex) const
{
	return String (channelIndex + 1);
}

const String SynthesizerAudioProcessor::getOutputChannelName (int channelIndex) const
{
	return String (channelIndex + 1);
}

bool SynthesizerAudioProcessor::isInputChannelStereoPair (int index) const
{
	return true;
}

bool SynthesizerAudioProcessor::isOutputChannelStereoPair (int index) const
{
	return true;
}

bool SynthesizerAudioProcessor::acceptsMidi() const
{
   #if JucePlugin_WantsMidiInput
	return true;
   #else
	return false;
   #endif
}

bool SynthesizerAudioProcessor::producesMidi() const
{
   #if JucePlugin_ProducesMidiOutput
	return true;
   #else
	return false;
   #endif
}

bool SynthesizerAudioProcessor::silenceInProducesSilenceOut() const
{
	return false;
}

double SynthesizerAudioProcessor::getTailLengthSeconds() const
{
	return 0.0;
}

//==============================================================================
void SynthesizerAudioProcessor::prepareToPlay (double sampleRate, int samplesPerBlock)
{
	// Use this method as the place to do any pre-playback
	// initialisation that you need..
	synth.setCurrentPlaybackSampleRate(sampleRate);
	keyboardState.reset();
	directFormFilter.setSampleRate(sampleRate);
}

void SynthesizerAudioProcessor::releaseResources()
{
	// When playback stops, you can use this as an opportunity to free up any
	// spare memory, etc.
	keyboardState.reset();
}

void SynthesizerAudioProcessor::processBlock (AudioSampleBuffer& buffer, MidiBuffer& midiMessages)
{
	const int numSamples = buffer.getNumSamples();
	int channel = 0;

	// Pass any incoming MIDI messages to the keyboard state object, and let it
	// add messages to the buffer if the user is clicking on the on-screen keys.
	keyboardState.processNextMidiBuffer(midiMessages, 0, numSamples, true);

	// Get the Synth to process these midi events and generate its output.
	synth.renderNextBlock(buffer, midiMessages, 0, numSamples);

	// Apply filter to the new output:
	for (channel = 0; channel < getNumInputChannels(); ++channel)
	{
		float* channelData = buffer.getWritePointer (channel);

		for (int i = 0; i < numSamples; ++i) {
			const float in = channelData[i];

			// Process the audio buffer through the TransDirectFormIIFilter
			channelData[i] = directFormFilter.processChannel(in, channel);

			// Apply the gain to the audio buffer by simply multiplying it
			channelData[i] *= outputGain->getValue();
		}
	}

	// In case we have more outputs than inputs, this code clears any output
	// channels that didn't contain input data, (because these aren't
	// guaranteed to be empty - they may contain garbage).
	for (int i = getNumInputChannels(); i < getNumOutputChannels(); ++i)
		buffer.clear (i, 0, buffer.getNumSamples());

	// ask the host for the current time so we can display it...
	AudioPlayHead::CurrentPositionInfo newTime;

	if (getPlayHead() != nullptr && getPlayHead()->getCurrentPosition (newTime)) {
		// Successfully got the current time from the host..
		lastPosInfo = newTime;
	}
	else {
		// If the host fails to fill-in the current time, we'll just clear it to a default..
		lastPosInfo.resetToDefault();
	}
}

//==============================================================================

AudioProcessorEditor* SynthesizerAudioProcessor::createEditor()
{
	return new SynthesizerAudioProcessorEditor (*this);
}

//==============================================================================
void SynthesizerAudioProcessor::getStateInformation (MemoryBlock& destData)
{
	// You should use this method to store your parameters in the memory block.
	// Here's an example of how you can use XML to make it easy and more robust:

	// Create an outer XML element..
	XmlElement xml ("MYPLUGINSETTINGS");

	// add some attributes to it..
	xml.setAttribute ("uiWidth", lastUIWidth);
	xml.setAttribute ("uiHeight", lastUIHeight);
	xml.setAttribute ("outputGain", outputGain->getValue());
	xml.setAttribute("semitones", semitones->getValue());
	xml.setAttribute("cents", cents->getValue());
	xml.setAttribute("filterType", filterType->getValue());
	xml.setAttribute("cutoff", cutoff->getValue());
	xml.setAttribute("resonance", resonance->getValue());
	xml.setAttribute("peakGain", peakGaindB->getValue());

	// then use this helper function to stuff it into the binary blob and return it..
	copyXmlToBinary (xml, destData);
}

void SynthesizerAudioProcessor::setStateInformation (const void* data, int sizeInBytes)
{
	// You should use this method to restore your parameters from this memory block,
	// whose contents will have been created by the getStateInformation() call.

	// This getXmlFromBinary() helper function retrieves our XML from the binary blob..
	ScopedPointer<XmlElement> xmlState{ getXmlFromBinary(data, sizeInBytes) };

	if (xmlState != nullptr) {
		// make sure that it's actually our type of XML object..
		if (xmlState->hasTagName("MYPLUGINSETTINGS")) {
			// ok, now pull out our parameters..
			lastUIWidth  = xmlState->getIntAttribute ("uiWidth", lastUIWidth);
			lastUIHeight = xmlState->getIntAttribute ("uiHeight", lastUIHeight);

			outputGain->setValue(xmlState->getDoubleAttribute ("outputGain", outputGain->getValue()));
			semitones->setValue(xmlState->getDoubleAttribute("semitones", semitones->getValue()));
			cents->setValue(xmlState->getDoubleAttribute("cents", cents->getValue()));
			filterType->setValue(xmlState->getDoubleAttribute("filterType", filterType->getValue()));
			cutoff->setValue(xmlState->getDoubleAttribute("cutoff", cutoff->getValue()));
			resonance->setValue(xmlState->getDoubleAttribute("resonance", resonance->getValue()));
			peakGaindB->setValue(xmlState->getDoubleAttribute("peakGain", peakGaindB->getValue()));
		}
	}
}

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
	return new SynthesizerAudioProcessor();
}
